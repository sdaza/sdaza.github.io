<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://sdaza.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sdaza.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-05T12:14:24+00:00</updated><id>https://sdaza.com/feed.xml</id><title type="html">blank</title><subtitle>Demography, Sociology, Simulation, Data Science</subtitle><entry><title type="html">Tools for power analysis with multiple comparisons</title><link href="https://sdaza.com/blog/2023/statistical-power/" rel="alternate" type="text/html" title="Tools for power analysis with multiple comparisons"/><published>2023-09-26T00:00:00+00:00</published><updated>2023-09-26T00:00:00+00:00</updated><id>https://sdaza.com/blog/2023/statistical-power</id><content type="html" xml:base="https://sdaza.com/blog/2023/statistical-power/"><![CDATA[<p>This post will discuss tools for designing and evaluating experiments. These tools offer user-friendly methods to estimate statistical power when working with multiple treatments or variants. They also help with sample allocation, including determining sample sizes for treatment and control groups. Lastly, they estimate power based on different expected effects (e.g., minimum detectable effects or MDE).</p> <p>Calculating power for complex and uplift models using machine learning can be challenging. I will provide some general guidelines and references at the end of this post.</p> <h2 id="lets-start-with-some-terms">Let’s start with some terms</h2> <p>When conducting a statistical test to estimate an effect, we can have any of the following outcomes:</p> <p align="center"> <img src="/assets/img/pregnant-power.jpg" alt="Image" width="70%" height="70%"/> </p> <p>These errors and success probabilities are associated with standard statistical terms used in making inferences.</p> <ul> <li><strong>Type I Error (\(\alpha\))</strong>: the probability of rejecting the null hypothesis when it’s true.</li> <li><strong>Type II Error (\(\beta\))</strong>: the probability of failing to reject the null hypothesis when it’s false.</li> <li><strong>Power (\(1-\beta\))</strong>: the probability of rejecting the null hypothesis when it’s false.</li> <li><strong>Confidence (\(1-\alpha\))</strong>: the probability of failing to reject the null hypothesis when it’s true.</li> </ul> <p>As a standard, \(\alpha\) is set to 0.05 and power to .80. Also, we will generally have a control group (no intervention) and different treatments (variants). </p> <h2 id="there-are-some-challenges">There are some challenges</h2> <p>There are some challenges associated with basic power calculations (e.g., web calculators): </p> <ul> <li><strong>(Simultaneous) multiple comparisons</strong></li> <li><strong>Sample allocation</strong></li> <li><strong>Different MDEs by variant</strong></li> </ul> <p>When conducting multiple statistical tests or comparisons within a study or analysis, there is a risk of obtaining false positive results. To address this, we need to adjust our \(\alpha\) level based on the number of tests performed. This adjustment increases the required sample size to achieve statistical significance. It is important to consider this issue during experiment design and data analysis, including post hoc analyses.</p> <p>To gain an understanding of why multiple comparison testing poses a challenge, let’s consider a simple example. Suppose we have a control group and three treatment variants. In this example, we will simulate data where there are no effects or differences between the control and treatment groups. In other words, the null hypothesis (i.e., no effect) is always true. In each iteration, we test the control group against each treatment and count the number of significant results we obtain using a significance level (\(\alpha=0.05\)). It is important to note that we already know there are no differences between the groups.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">"</span><span class="s">display.notebook_repr_html</span><span class="sh">"</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Number of iterations for simulation
</span><span class="n">iterations</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Number of treatment groups
</span><span class="n">groups</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># Number of samples in each group
</span><span class="n">samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Count of batches where at least one false positive (Type I error) occurs
</span><span class="n">batches_with_errors</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># perform iterations
</span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
    <span class="c1"># Control group data
</span>    <span class="n">control_group</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>

    <span class="c1"># Treatment group data - no actual difference from control
</span>    <span class="n">treatment_groups</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">groups</span><span class="p">)]</span>

    <span class="c1"># A flag for any error within this batch of tests
</span>    <span class="n">error_in_batch</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="c1"># perform t-test for each treatment group compared to control group
</span>    <span class="k">for</span> <span class="n">treatment</span> <span class="ow">in</span> <span class="n">treatment_groups</span><span class="p">:</span>
        <span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="nf">ttest_ind</span><span class="p">(</span><span class="n">control_group</span><span class="p">,</span> <span class="n">treatment</span><span class="p">)</span>

        <span class="c1"># Check if p-value is less than 0.05 (significance level)
</span>        <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
            <span class="n">error_in_batch</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">break</span>  <span class="c1"># no need to check remaining tests
</span>
    <span class="k">if</span> <span class="n">error_in_batch</span><span class="p">:</span>
        <span class="n">batches_with_errors</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Probability of at least one Type I error in a batch of </span><span class="si">{</span><span class="n">groups</span><span class="si">}</span><span class="s"> tests: </span><span class="si">{</span><span class="n">batches_with_errors</span> <span class="o">/</span> <span class="n">iterations</span> <span class="o">*</span> <span class="mi">100</span><span class="si">}</span><span class="s">%</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Probability of at least one Type I error in a batch of 3 tests: 12.6%
</code></pre></div></div> <p>After 1000 iterations, the probability of encountering at least one Type I error in a batch of 3 tests is 12.6%. You can also use the formula:</p> \[1 - (1 - \alpha)^n\] <p>Where \(n\) is the number of comparisons. For this example, FWER will be 14.2%. This probability is referred to as the <strong>Family-wise Error Rate (FWER)</strong>, which signifies the likelihood of committing at least one Type I error within the entire family (or batch) of comparisons. It is evident that 12.6% and 14.2% are higher than the assumed α value of 5% for a single test.</p> <p>This is the essence of the multiple comparison problem. When conducting multiple tests, even if you maintain an \(\alpha\) level of approximately 0.05 for each individual test, the likelihood of experiencing at least one false discovery among the entire set of tests is significantly higher and increases as the number of tests in the batch grows. Consequently, some of our significant findings may actually be false positives and difficult to replicate.</p> <p>The key to adjusting multiple comparison testing is to strike a balance between reducing false positives (incorrectly rejecting the null hypothesis) and maintaining test power (the ability to correctly reject the null hypothesis when it’s false). Some methods, such as <em>Bonferroni</em> or <em>Holm</em>, minimize the <strong>Family-Wise Error Rate (FWER)</strong>. Others, like <em>Benjamini-Hochberg</em>, minimize the <strong>False Discovery Rate (FDR)</strong>, which is the expected proportion of Type I errors among all declared significant hypotheses. FDR methods aim to reduce the ratio of Type I errors among significant results without eliminating all false discoveries like FWER methods. FDR methods generally offer higher statistical power and are less conservative.</p> <p>A crucial element of experimental design lies in sample allocation. Variations in the distribution of samples among groups can influence the statistical power of our tests. Sometimes, the goal is to limit the potential disruption from an intervention by scaling down the sample size across various variants. Alternatively, we might opt to shrink the control group’s size or allot more units to each variant, contingent on their Minimum Detectable Effect (MDE).</p> <p>Let’s not forget to consider expected effects. In figuring out the smallest minimum detectable effect (MDE), think about the least significant change that would still make the intervention worthwhile. It’s all about balancing the books: estimate the return on investment (ROI) from the intervention, then determine the tiniest shift in a key metric (like conversion rates) that would still make the effort profitable. The MDE doesn’t have to be identical across all variants - after all, not all interventions or campaigns cost the same.</p> <h2 id="tools-can-help">Tools can help</h2> <p>I’ve developed a set of straightforward simulation methods in Python, primarily to construct and evaluate our experimental data. The choice to use simulation was driven by its flexibility in handling diverse scenarios and metrics. However, it does come with a trade-off, as it demands a higher computational power. We can live with that :smile:. <a href="https://github.com/sdaza/sdaza.github.io/tree/main/_jupyter/power_tools.py">Feel free to explore the code for the power class</a>.</p> <p>These methods are useful, particularly for handling multiple variants, different allocations, or MDE by group. However, it’s important to note that these methods only offer a power estimate based on a given set of parameters. Therefore, we will need to conduct a grid search to evaluate various scenarios and determine the optimal one.</p> <p>Let’s start with a simple example using a proportion as the metric of interest:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">power_tools</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># load class
</span><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">proportion</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nsim</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># get power
</span><span class="n">p</span><span class="p">.</span><span class="nf">get_power</span><span class="p">(</span><span class="n">baseline</span><span class="o">=</span><span class="p">[</span><span class="mf">0.33</span><span class="p">],</span> <span class="n">effect</span><span class="o">=</span><span class="p">[</span><span class="mf">0.03</span><span class="p">],</span> <span class="n">sample_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3000</span><span class="p">])</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  comparisons  power
0      (0, 1)  0.706
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">nsim</code> represents the number of simulations. Variants are set to 1, so we are only comparing control and treatment: <code class="language-plaintext highlighter-rouge">comparisons = (0,1)</code>. This example is too simple. Let’s now assume two variants (treatments): </p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">proportion</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
             <span class="n">nsim</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="nf">get_power</span><span class="p">(</span><span class="n">baseline</span><span class="o">=</span><span class="p">[</span><span class="mf">0.33</span><span class="p">],</span> <span class="n">effect</span><span class="o">=</span><span class="p">[</span><span class="mf">0.03</span><span class="p">],</span> <span class="n">sample_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3000</span><span class="p">])</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  comparisons  power
0      (0, 1)  0.531
1      (0, 2)  0.530
2      (1, 2)  0.015
</code></pre></div></div> <p>The function calculates the power of group comparisons with a sample size of 3000 for each group. Multiple comparisons result in reduced power. Since the effect of each variant is the same (0.03), comparing <em>variants 1 and 2</em> is not meaningful here (it will always be 0 in practice). Custom comparisons can be defined using a list of tuples, such as <code class="language-plaintext highlighter-rouge">comparisons=[(0,1), (0,2)]</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">proportion</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
             <span class="n">nsim</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">,</span>
             <span class="n">comparisons</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)])</span>
<span class="n">p</span><span class="p">.</span><span class="nf">get_power</span><span class="p">(</span><span class="n">baseline</span><span class="o">=</span><span class="p">[</span><span class="mf">0.33</span><span class="p">],</span> <span class="n">effect</span><span class="o">=</span><span class="p">[</span><span class="mf">0.03</span><span class="p">],</span> <span class="n">sample_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3000</span><span class="p">])</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  comparisons  power
0      (0, 1)  0.558
1      (0, 2)  0.563
</code></pre></div></div> <p>Using only two comparisons (each variant with a control), the power significantly decreases compared to the one-variant example. I have currently implemented the following p-value corrections:</p> <ul> <li><code class="language-plaintext highlighter-rouge">bonferroni</code></li> <li><code class="language-plaintext highlighter-rouge">holm_bonferroni</code></li> <li><code class="language-plaintext highlighter-rouge">hochberg</code></li> <li><code class="language-plaintext highlighter-rouge">sidak</code></li> <li><code class="language-plaintext highlighter-rouge">fdr</code></li> </ul> <p>You can find an introduction to different methods <a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem">here</a>. In general, Bonferroni is more conservative, while Holm provides higher power. The <code class="language-plaintext highlighter-rouge">fdr</code> method aims to minimize the false discovery rate.</p> <p>The function corrects only for the comparisons specified in the <code class="language-plaintext highlighter-rouge">comparisons</code> parameter. If you conduct additional tests, such as comparing the performance of group A versus group B or examining differences among demographic groups, you need to apply additional multiple comparison corrections in your analysis.</p> <p>We can introduce greater variability into the experimental design. We can then plot the expected power for different scenarios. To specify parameters, we’ll utilize nested lists and the <code class="language-plaintext highlighter-rouge">grid_sim_power</code> method. However, things can quickly become convoluted.</p> <p>Let’s consider a more complex example. The impact of the first and second variants on the control group varies as follows: <code class="language-plaintext highlighter-rouge">[0.01, 0.03]</code>, <code class="language-plaintext highlighter-rouge">[0.03, 0.05]</code>, <code class="language-plaintext highlighter-rouge">[0.03, 0.07]</code>. The sample sizes are equal for each group, but they increase linearly. We apply the <code class="language-plaintext highlighter-rouge">holm</code> correction.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">proportion</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">,</span> 
	<span class="n">nsim</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="sh">'</span><span class="s">holm</span><span class="sh">'</span><span class="p">)</span>
<span class="n">rr</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="nf">grid_sim_power</span><span class="p">(</span><span class="n">baseline_rates</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.33</span><span class="p">]],</span> 
                <span class="n">effects</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">]],</span>
                <span class="n">sample_sizes</span><span class="o">=</span> <span class="p">[[</span><span class="mi">1000</span><span class="p">],</span> <span class="p">[</span><span class="mi">2000</span><span class="p">],</span> <span class="p">[</span><span class="mi">3000</span><span class="p">],</span> <span class="p">[</span><span class="mi">4000</span><span class="p">],</span> <span class="p">[</span><span class="mi">5000</span><span class="p">],</span> <span class="p">[</span><span class="mi">6000</span><span class="p">],</span> <span class="p">[</span><span class="mi">7000</span><span class="p">],</span> <span class="p">[</span><span class="mi">8000</span><span class="p">],</span> <span class="p">[</span><span class="mi">9000</span><span class="p">]],</span> 
                <span class="n">threads</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
                <span class="n">plot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2023-09-26-statistical-power_files/2023-09-26-statistical-power_10_0.png" alt="png"/></p> <p><img src="/assets/img/2023-09-26-statistical-power_files/2023-09-26-statistical-power_10_1.png" alt="png"/></p> <p><img src="/assets/img/2023-09-26-statistical-power_files/2023-09-26-statistical-power_10_2.png" alt="png"/></p> <p>As expected, the best scenario occurs when the effect sizes are large enough to be detected. We can also analyze the results of different sample allocations. For example, when we look at the effects <code class="language-plaintext highlighter-rouge">[0.03, 0.05]</code>, the allocation <code class="language-plaintext highlighter-rouge">[3000, 7000, 7000]</code> produces fairly good results, although it doesn’t always meet the 0.8 threshold.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">proportion</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
             <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">,</span> <span class="n">nsim</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="sh">'</span><span class="s">holm</span><span class="sh">'</span><span class="p">)</span>
<span class="n">rr</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="nf">grid_sim_power</span><span class="p">(</span><span class="n">baseline_rates</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.33</span><span class="p">]],</span> 
                <span class="n">effects</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">]],</span>
                <span class="n">sample_sizes</span><span class="o">=</span> <span class="p">[[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3000</span><span class="p">,</span> <span class="mi">3000</span><span class="p">],</span> 
                               <span class="p">[</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">],</span> 
                               <span class="p">[</span><span class="mi">3000</span><span class="p">,</span> <span class="mi">7000</span><span class="p">,</span> <span class="mi">7000</span><span class="p">],</span> 
                               <span class="p">[</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">8000</span><span class="p">,</span> <span class="mi">8000</span><span class="p">],</span>
                               <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">8000</span><span class="p">,</span> <span class="mi">8000</span><span class="p">]],</span>
                <span class="n">threads</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
                <span class="n">plot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2023-09-26-statistical-power_files/2023-09-26-statistical-power_12_0.png" alt="png"/></p> <p><img src="/assets/img/2023-09-26-statistical-power_files/2023-09-26-statistical-power_12_1.png" alt="png"/></p> <p><img src="/assets/img/2023-09-26-statistical-power_files/2023-09-26-statistical-power_12_2.png" alt="png"/></p> <p>We can also use other metrics (e.g., average or counts).  For instance, we can design an experiment where the outcome is the number of visits (counts). The simulator will use a Poisson distribution with the parameter, \(\lambda\) (lambda) or the mean number of events. In this example, I set a baseline rate (lambda) of 1.2 visits and a relative increase of \(0.05 (1.2*1.05) = 1.26\), with a control group of 3000 users and a treatment of 5000 users:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="nf">get_power</span><span class="p">(</span><span class="n">baseline</span><span class="o">=</span><span class="p">[</span><span class="mf">1.2</span><span class="p">],</span> <span class="n">effect</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">],</span> <span class="n">sample_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  comparisons  power
0      (0, 1)   0.59
</code></pre></div></div> <p>The effect is small, so our test is underpowered (&lt;0.80). We can also use averages (e.g., revenue), but in that case, we need to specify the standard deviation of the groups:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="nc">PowerSim</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">average</span><span class="sh">'</span><span class="p">,</span> <span class="n">relative_effect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">variants</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="sh">'</span><span class="s">two-tailed</span><span class="sh">'</span><span class="p">,</span> <span class="n">nsim</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="nf">get_power</span><span class="p">(</span><span class="n">baseline</span><span class="o">=</span><span class="p">[</span><span class="mi">1000</span><span class="p">],</span> <span class="n">effect</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">],</span> <span class="n">standard_deviation</span><span class="o">=</span><span class="p">[</span><span class="mi">600</span><span class="p">],</span> <span class="n">sample_size</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">])</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  comparisons   power
0      (0, 1)  0.6592
</code></pre></div></div> <h2 id="complex-models">Complex models </h2> <p>When using uplift or mixed models, things become more complicated. As Aleksander Molak put it:</p> <blockquote> <p>The question of defining a “safe” dataset size for S-Learner and other causal models is difficult to answer. Power calculations for machine learning models are often difficult, if possible at all. </p> </blockquote> <p>There are some tricks we can apply, though, as Harrell suggests:</p> <blockquote> <p>If you can afford a pilot study or you have some historical data that represents a problem similar to the one that you’re interested in, you can find a subgroup in your data that is as homogenous as possible. You can estimate the sample size for this group using some of the traditional statistical power tools. Finally, scale your overall sample size so that this subgroup is properly powered relative to the entire sample</p> </blockquote> <p>There are also some traditional ways to optimize the power of our tests:</p> <ul> <li>Blocking design</li> <li>Stratification and covariate adjustments (regression)</li> </ul> <p>For instance, after learning from our uplift models, we can identify the key features associated to users’ responses. We can use those features to design our experiments (blocking). We can also evaluate the results of our uplift models in a new sample, and see if we can replicate the expected <code class="language-plaintext highlighter-rouge">uplift</code>.</p> <p>Here’s a brief and general overview of the key features to keep in mind when designing experiments or improving models. I hope it’s helpful.</p> <p><br/></p> <hr/> <h2 id="references">References</h2> <ul> <li>Molak, Aleksander. <em>Causal Inference and Discovery in Python: Unlock the secrets of modern causal machine learning with DoWhy, EconML, PyTorch and more</em> . </li> <li>https://www.fharrell.com/</li> <li>Ron Kohavi. <em>Trustworthy Online Controlled Experiments</em>.</li> </ul>]]></content><author><name>Sebastian Daza</name></author><category term="simulation"/><category term="python"/><category term="experiments"/><summary type="html"><![CDATA[This post will discuss tools for designing and evaluating experiments. These tools offer user-friendly methods to estimate statistical power when working with multiple treatments or variants. They also help with sample allocation, including determining sample sizes for treatment and control groups. Lastly, they estimate power based on different expected effects (e.g., minimum detectable effects or MDE).]]></summary></entry><entry><title type="html">Extracting Zotero’s notes</title><link href="https://sdaza.com/blog/2021/zotero-notes/" rel="alternate" type="text/html" title="Extracting Zotero’s notes"/><published>2021-07-06T00:00:00+00:00</published><updated>2021-07-06T00:00:00+00:00</updated><id>https://sdaza.com/blog/2021/zotero-notes</id><content type="html" xml:base="https://sdaza.com/blog/2021/zotero-notes/"><![CDATA[<p>When reviewing the literature, it’s nice to have the notes linked to Zotero references. It would also be great to compare them systematically. The idea would be to have your notes in Zotero so that everyone in the group can access and edit them and create a data file to explore your notes using, for instance, text analysis techniques.</p> <p>This small package extracts notes from a collection and creates a CSV file that can be easily read using Excel. You only need to specify the collection ID. For instance, if the location of my collection is <code class="language-plaintext highlighter-rouge">https://www.zotero.org/groups/2406179/csic-echo/collections/M8N2VMAP</code>, the collection ID would be <code class="language-plaintext highlighter-rouge">M8N2VMAP</code>. We also need the Zotero API’s credentials.</p> <p>To create a clean CSV, notes’ headers would need a suitable separator. The default is <code class="language-plaintext highlighter-rouge">#</code>. In this case, the text between headings mustn’t include <code class="language-plaintext highlighter-rouge">#</code>. Below an example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Research question

Estimates interaction effects between PGS of obesity and cohorts using HRS.

# Data

HRS

# Methods

Uses a HLM whereby they estimate effects of age and cohorts while making the
intercepts and slopes a function of individual factors.
</code></pre></div></div> <h2 id="installation">Installation</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install git+https://github.com/sdaza/zotnote.git
</code></pre></div></div> <h2 id="credentials">Credentials</h2> <p>You can save your Zotero API credentials in a <code class="language-plaintext highlighter-rouge">config.py</code> and load them using <code class="language-plaintext highlighter-rouge">import config</code>:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">library_id = "0000000"</span>
<span class="s">api_key = "key"</span>
<span class="s">library_type = "group"</span>
</code></pre></div></div> <h2 id="example">Example</h2> <p>Let’s try to extract some notes and read them using Pandas:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">config</span>
<span class="kn">import</span> <span class="n">zotnote</span> <span class="k">as</span> <span class="n">zn</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">zn</span><span class="p">.</span><span class="nf">exportNotes</span><span class="p">(</span><span class="n">collection</span> <span class="o">=</span> <span class="sh">"</span><span class="s">M8N2VMAP</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">library_id</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">library_id</span><span class="p">,</span> <span class="n">api_key</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">api_key</span><span class="p">)</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Notes saved in zotero-notes.csv
</code></pre></div></div> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">zotero-notes.csv</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/zotnotes.png" alt="center"/></p>]]></content><author><name>Sebastian Daza</name></author><category term="zotero"/><summary type="html"><![CDATA[How to extract zotero notes to CSV / Excel file]]></summary></entry><entry><title type="html">From database to CSV using Anylogic</title><link href="https://sdaza.com/blog/2020/anylogic-database/" rel="alternate" type="text/html" title="From database to CSV using Anylogic"/><published>2020-11-03T00:00:00+00:00</published><updated>2020-11-03T00:00:00+00:00</updated><id>https://sdaza.com/blog/2020/anylogic-database</id><content type="html" xml:base="https://sdaza.com/blog/2020/anylogic-database/"><![CDATA[<p>When running a parameter variation experiment, that is, simulating over several iterations and replicates using parallelization, we usually need to collect a huge amount of data and have them in a format that then we can process using Python or R.</p> <p>The best way to do this in Anylogic would be using a database and then export, read, or connect to the database to process simulation results (although, see the section <strong>update</strong> below). We can do that easily in Anylogic. Every time an experiment finishes, we can export the data (from a database) to an Excel file manually.</p> <p>The issue with Excel files is, on the one hand, they are Excel files, and on the other, they are not suitable for big data (more than 1 million rows). We can create a function to save all the simulation tables into an Excel file as our experiment finishes. However, we will still have the limit-of-rows limitation (check the Anylogic file linked below for a function to create Excel files from a database).</p> <p>Here I follow a different approach by exporting an Anylogic database table to a CSV file within Java. The general setup using Anylogic PLE 8.6 would be:</p> <ul> <li>Create the databases you need for your experiment, and be sure you add the columns iteration and replicate.</li> <li>Create a function to save the data of your simulation runs (e.g., agent’s status, age, etc.)</li> <li>Define a parameter variation experiment.</li> <li>Define a variable to specify where to save the data (i.e., path).</li> <li>Write code in the experiment Java Actions section so that to save data every time you run an experiment.</li> <li>Import functions in the advanced Java section of the experiment.</li> </ul> <h2 id="databases">Databases</h2> <p>I define two tables (<code class="language-plaintext highlighter-rouge">data1</code> and <code class="language-plaintext highlighter-rouge">data2</code>). Each agent saves its data at a given rate. After 5 years, the simulation will finish.</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">insertInto</span><span class="o">(</span><span class="n">data1</span><span class="o">)</span>
    <span class="o">.</span><span class="na">columns</span><span class="o">(</span><span class="n">data1</span><span class="o">.</span><span class="na">iteration</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">replicate</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">id</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">dtime</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">drandom</span><span class="o">)</span>
    <span class="o">.</span><span class="na">values</span><span class="o">(</span><span class="n">main</span><span class="o">.</span><span class="na">v_iteration</span><span class="o">,</span> <span class="n">main</span><span class="o">.</span><span class="na">v_replicate</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="na">getIndex</span><span class="o">(),</span> <span class="n">time</span><span class="o">(),</span> <span class="n">normal</span><span class="o">(</span><span class="mf">1.0</span><span class="o">))</span>
    <span class="o">.</span><span class="na">execute</span><span class="o">();</span>

<span class="n">insertInto</span><span class="o">(</span><span class="n">data2</span><span class="o">)</span>
    <span class="o">.</span><span class="na">columns</span><span class="o">(</span><span class="n">data2</span><span class="o">.</span><span class="na">iteration</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">replicate</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">id</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">dtime</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">drandom</span><span class="o">)</span>
    <span class="o">.</span><span class="na">values</span><span class="o">(</span><span class="n">main</span><span class="o">.</span><span class="na">v_iteration</span><span class="o">,</span> <span class="n">main</span><span class="o">.</span><span class="na">v_replicate</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="na">getIndex</span><span class="o">(),</span> <span class="n">time</span><span class="o">(),</span> <span class="n">normal</span><span class="o">(</span><span class="mf">0.3</span><span class="o">))</span>
    <span class="o">.</span><span class="na">execute</span><span class="o">();</span>

<span class="k">if</span> <span class="o">(</span><span class="n">time</span><span class="o">()</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">finishSimulation</span><span class="o">();</span>
<span class="o">}</span></code></pre></figure> <p>The tables include a column with the experiment iteration and replicate, in addition to the agent’s index, time, and a random value from a normal distribution.</p> <h2 id="from-db-to-csv">From DB to CSV</h2> <p>The key function to export the data to a CSV file is <code class="language-plaintext highlighter-rouge">f_SQLToCSV</code>. It uses two arguments, a SQL query (<code class="language-plaintext highlighter-rouge">query</code>) and the path to an output file (<code class="language-plaintext highlighter-rouge">filename</code>). For instance, we can write:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">f_SQLToCSV</span><span class="o">(</span><span class="s">"select * from data1"</span><span class="o">,</span> <span class="s">"output/data1"</span><span class="o">)</span></code></pre></figure> <p>You can use any query for your data, giving you a lot of flexibility on what to export to a CSV file. The <code class="language-plaintext highlighter-rouge">f_SQLToCSV</code> method is:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">ResultSet</span> <span class="n">rs</span> <span class="o">=</span> <span class="n">selectResultSet</span><span class="o">(</span><span class="n">query</span><span class="o">);</span>
<span class="k">try</span> <span class="o">{</span>
    <span class="nc">File</span> <span class="n">file</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s">".csv"</span><span class="o">);</span>
    <span class="n">file</span><span class="o">.</span><span class="na">getParentFile</span><span class="o">().</span><span class="na">mkdirs</span><span class="o">();</span>
    <span class="nc">FileWriter</span> <span class="n">fw</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FileWriter</span><span class="o">(</span><span class="n">file</span><span class="o">);</span>
    <span class="kt">int</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="na">getMetaData</span><span class="o">().</span><span class="na">getColumnCount</span><span class="o">();</span>
    <span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">cols</span><span class="o">;</span> <span class="n">i</span> <span class="o">++){</span>
        <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">rs</span><span class="o">.</span><span class="na">getMetaData</span><span class="o">().</span><span class="na">getColumnLabel</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="na">toLowerCase</span><span class="o">());</span>
        <span class="k">if</span><span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="o">)</span> <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">';'</span><span class="o">);</span>
        <span class="k">else</span> <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">'\n'</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">rs</span><span class="o">.</span><span class="na">next</span><span class="o">())</span> <span class="o">{</span>
        <span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">cols</span><span class="o">;</span> <span class="n">i</span> <span class="o">++){</span>
            <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">rs</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">i</span><span class="o">));</span>
            <span class="k">if</span><span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="o">)</span> <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">';'</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">'\n'</span><span class="o">);</span>
     <span class="o">}</span>
     <span class="n">fw</span><span class="o">.</span><span class="na">flush</span><span class="o">();</span>
     <span class="n">fw</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">getEngine</span><span class="o">().</span><span class="na">pause</span><span class="o">();</span>
    <span class="n">traceln</span><span class="o">(</span><span class="s">"--&gt; An Exception happened, continue? ..."</span><span class="o">);</span>
    <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
<span class="o">}</span></code></pre></figure> <p>The next step would be to create an experiment and complete the Java actions accordingly. First, we clear our tables.</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// inital experiment setup</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data1</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span></code></pre></figure> <p>Then, we collect information on the iteration and replicate of the simulation run:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// before simulation run</span>
<span class="n">root</span><span class="o">.</span><span class="na">v_iteration</span> <span class="o">=</span> <span class="n">getCurrentIteration</span><span class="o">();</span>
<span class="n">root</span><span class="o">.</span><span class="na">v_replicate</span> <span class="o">=</span> <span class="n">getCurrentReplication</span><span class="o">();</span></code></pre></figure> <p>Finally, at the end of the experiment, we save the data and clear the tables again:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// after experiment</span>
<span class="n">f_exportTables</span><span class="o">(</span><span class="n">v_path</span><span class="o">);</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data1</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data1</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span></code></pre></figure> <p>The method <code class="language-plaintext highlighter-rouge">f_exportTables</code> is just a function that goes through each table and export them to a CSV file. <code class="language-plaintext highlighter-rouge">v_tables</code> is string array with the name of the tables I want to export <code class="language-plaintext highlighter-rouge">{"data1", "data2"}</code>:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">tables</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;();</span>
<span class="k">for</span><span class="o">(</span><span class="nc">String</span> <span class="n">tab</span> <span class="o">:</span> <span class="n">v_tables</span><span class="o">)</span> <span class="o">{</span>
   <span class="n">tables</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">tab</span><span class="o">);</span>
<span class="o">}</span>
<span class="k">for</span> <span class="o">(</span><span class="nc">String</span> <span class="n">t</span> <span class="o">:</span> <span class="n">tables</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">f_SQLToCSV</span><span class="o">(</span><span class="s">"select * from "</span> <span class="o">+</span> <span class="n">t</span><span class="o">,</span> <span class="n">path</span> <span class="o">+</span> <span class="n">t</span><span class="o">);</span>
<span class="o">}</span></code></pre></figure> <p>Remember to import some functions in the <code class="language-plaintext highlighter-rouge">imports section</code>:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// imports section</span>
<span class="kn">import</span> <span class="nn">java.io.BufferedWriter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.File</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.FileWriter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.BufferedReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.FileReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.text.*</span><span class="o">;</span></code></pre></figure> <p>From there, we can create additional functions to select the tables to be exported. For more details, download the <a href="/assets/files/DBToCSV.zip">Anylogic File here</a>.</p> <h2 id="update">Update</h2> <p>When running several replicates of my simulation, saving the information in a database didn’t work as expected. My simulation just crashed, and I was not able to keep the data. I finally decided to follow my previous approach: create many CSV files – one per iteration and replicate – and read them using an R or Python function. I know you end up with a lot of CSV files, but at least the simulation doesn’t crash, and you can recover the output of your simulation as it goes.</p>]]></content><author><name>Sebastian Daza</name></author><category term="anylogic"/><category term="simulation"/><summary type="html"><![CDATA[How to transform a database into CSV using Anylogic]]></summary></entry><entry><title type="html">Oh, descriptive tables (R + Latex)!</title><link href="https://sdaza.com/blog/2020/descriptive-tables/" rel="alternate" type="text/html" title="Oh, descriptive tables (R + Latex)!"/><published>2020-05-12T00:00:00+00:00</published><updated>2020-05-12T00:00:00+00:00</updated><id>https://sdaza.com/blog/2020/descriptive-tables</id><content type="html" xml:base="https://sdaza.com/blog/2020/descriptive-tables/"><![CDATA[<p>It’s been a while since my last post. It’s time to catch up!</p> <p>Every time I write a paper or report, I need to create descriptive tables using Latex. Over and over I create Adhoc tables, and I say to myself: <em>Write a general function so you can save time in the next paper!</em> I know there are some solutions out there, but in general, I feel they are not flexible enough.</p> <p>I introduce a far from perfect function to create descriptive tables in Latex. The steps and structure are quite simple:</p> <ol> <li>Write a function to summarize your data with any stats you want</li> <li>Define a list with the data plus column names (labels)</li> </ol> <p>That’s it. You can see the function <a href="https://gist.github.com/sdaza/c4d1089a501d3567be9fb784b1c5a6ab">here</a>. It has some features might be useful:</p> <ul> <li>It deals automatically with factors (categorical variables)</li> <li>You can use different datasets at the same time</li> <li>You can group columns using a variable (e.g., year)</li> <li>You can add long notes at the bottom of the table</li> <li>You can specify your own descriptive function</li> </ul> <p>Let’s start creating some fake data:</p> <ul> <li>5 variables</li> <li>Variable 3 is a factor (i.e., categorical)</li> <li>Variable 5 is a grouping column</li> </ul> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">14332</span><span class="p">)</span><span class="w">
</span><span class="n">devtools</span><span class="o">::</span><span class="n">source_gist</span><span class="p">(</span><span class="s2">"c4d1089a501d3567be9fb784b1c5a6ab"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create two fake datasets</span><span class="w">
</span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">dat1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="w">
    </span><span class="n">var1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">n1</span><span class="p">),</span><span class="w">
    </span><span class="n">var2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.8</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
    </span><span class="n">var3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="m">0.4</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">),</span><span class="w">
        </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
        </span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Low"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Medium"</span><span class="p">,</span><span class="w"> </span><span class="s2">"High"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Very high"</span><span class="p">)),</span><span class="w">
    </span><span class="n">var4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">),</span><span class="w">
    </span><span class="n">var5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">200</span><span class="w">
</span><span class="n">dat2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="w">
    </span><span class="n">var1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">),</span><span class="w">
    </span><span class="n">var2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
    </span><span class="n">var3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="m">0.35</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">),</span><span class="w">
        </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
        </span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Very low"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Low"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Medium"</span><span class="p">,</span><span class="w"> </span><span class="s2">"High"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Very high"</span><span class="p">)),</span><span class="w">
    </span><span class="n">var4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="m">2000</span><span class="p">,</span><span class="w"> </span><span class="m">300</span><span class="p">),</span><span class="w">
    </span><span class="n">var5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">datasets</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"Data 1"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dat1</span><span class="p">,</span><span class="w"> </span><span class="s2">"Data 2"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dat2</span><span class="p">)</span><span class="w">
</span><span class="n">variables</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"var"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"var"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">))</span><span class="w">
</span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Variable "</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Variable "</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Mean"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Median"</span><span class="p">,</span><span class="w"> </span><span class="s2">"SD"</span><span class="p">)</span></code></pre></figure> <p>We can define a descriptive function:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># descriptive function</span><span class="w">
</span><span class="n">myDescriptives</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
    </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">md</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">median</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="nf">return</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">md</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="p">))</span><span class="w">
</span><span class="p">}</span></code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create table</span><span class="w">
</span><span class="n">createDescriptiveTable</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span><span class="w">
    </span><span class="n">summary_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myDescriptives</span><span class="p">,</span><span class="w">
    </span><span class="n">column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
    </span><span class="n">arraystretch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w">
    </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Descriptive statistics"</span><span class="p">,</span><span class="w">
    </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tab:descriptive"</span><span class="p">,</span><span class="w">
    </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"example_01.tex"</span><span class="p">)</span></code></pre></figure> <div> <img src="/assets/img/table_examples/example_table_1.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%; height: 50%;"/> </div> <p>Thus, the grouping of rows is defined by the name of each dataset in the list. We can add a note, just remember to add <code class="language-plaintext highlighter-rouge">\usepackage[flushleft]{threeparttable}</code> to your Latex document:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># table + note</span><span class="w">
</span><span class="n">createDescriptiveTable</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span><span class="w">
    </span><span class="n">summary_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myDescriptives</span><span class="p">,</span><span class="w">
    </span><span class="n">column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
    </span><span class="n">arraystretch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w">
    </span><span class="n">note</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"This is a very long long long long long long long long long note."</span><span class="p">,</span><span class="w">
    </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Descriptive statistics"</span><span class="p">,</span><span class="w">
    </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tab:descriptive"</span><span class="p">,</span><span class="w">
    </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"example_02.tex"</span><span class="p">)</span></code></pre></figure> <div> <img src="/assets/img/table_examples/example_table_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%; height: 50%;"/> </div> <p>We can also slice the descriptives by group:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># group columns</span><span class="w">
</span><span class="n">createDescriptiveTable</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span><span class="w">
    </span><span class="n">summary_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myDescriptives</span><span class="p">,</span><span class="w">
    </span><span class="n">column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
    </span><span class="n">group_variable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"var5"</span><span class="p">,</span><span class="w">
    </span><span class="n">arraystretch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w">
    </span><span class="n">tabcolsep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w">
    </span><span class="n">note</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"This is a very long long long long long long long long long note."</span><span class="p">,</span><span class="w">
    </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Descriptive statistics"</span><span class="p">,</span><span class="w">
    </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tab:descriptive"</span><span class="p">,</span><span class="w">
    </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"example_03.tex"</span><span class="p">)</span></code></pre></figure> <div> <img src="/assets/img/table_examples/example_table_3.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%; height: 90%;"/> </div> <p>It’s just a first version. I will add more features soon.</p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="latex"/><summary type="html"><![CDATA[How to create latex descriptive tables in R]]></summary></entry><entry><title type="html">Reading CDC mortality files using R</title><link href="https://sdaza.com/blog/2016/read-mortality-data/" rel="alternate" type="text/html" title="Reading CDC mortality files using R"/><published>2016-10-05T00:00:00+00:00</published><updated>2016-10-05T00:00:00+00:00</updated><id>https://sdaza.com/blog/2016/read-mortality-data</id><content type="html" xml:base="https://sdaza.com/blog/2016/read-mortality-data/"><![CDATA[<p>Reading fixed-width text files might be challenging, specially when we don’t have a dictionary file. In this post, I show steps to read CDC files in a more systematic way. In this example, I import a compress mortality file (CMF 1979-1988) available <a href="http://www.cdc.gov/nchs/data_access/cmf.htm">here</a> and whose codebook (or layout) is <a href="http://www.cdc.gov/nchs/data/mortab/filelayout68_88.pdf">here</a>.</p> <p>To read this file, usually with extension <code class="language-plaintext highlighter-rouge">.txt</code> or <code class="language-plaintext highlighter-rouge">.dat</code>, I first need to know where each column starts and finishes. What I get from the pdf file is something like this:</p> <p><img src="/assets/img/mortalityLayout.png" alt=""/></p> <p>The layout is usually a codebook in Word/PDF or just plain text file. Here, I copy the PDF text and put it in a plain text file. I use a text editor (e.g., <a href="https://www.sublimetext.com/">Sublime Text</a>) and <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a> to extract the information I need.</p> <p>I have to select every row with this pattern: <code class="language-plaintext highlighter-rouge">1-2 2 FIPS State code Numeric</code>. That is, a number followed by a hyphen (although not always, particularly when the width of the column is one), spaces, another number, spaces, and then any text. I use the following regular expression to get that pattern: <code class="language-plaintext highlighter-rouge">(^[0-9]+).([0-9]+)\s+([0-9])\s+(.+)</code>. Using the Sublime package <a href="https://packagecontrol.io/packages/Filter%20Lines">Filter Lines</a> I get something like this (you can also just copy the selected lines):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1-2 2 FIPS State code Numeric
3-5 FIPS county code Numeric
6-9 4 Year of death Numeric
11-12 2 Age at death Numeric
13-16 4 ICD code for underlying cause-of-death 3 digits: Numeric
17-19 3 Cause-of-Death Recode Numeric
20-23 4 Number of deaths Numeric
</code></pre></div></div> <p>This approach might be particularly useful when you have a long PDF/Word file and you want to extract most of the variables. You would need to adapt the regular expressions I’m using to the particular patterns of your codebook.</p> <p>To simplify, I format this text as a comma-separated values file (csv). Replacing this regular expression <code class="language-plaintext highlighter-rouge">([0-9]+)(-)([0-9]+)(\s)([0-9]+)(\s)(.+)(\s)(Numeric)</code> by <code class="language-plaintext highlighter-rouge">\1,\3,\5,\7,\9</code> I get:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1,2,2,FIPS State code,Numeric
3,5,3,FIPS county code,Numeric
6,9,4,Year of death,Numeric
11,12,2,Age at death,Numeric
13,16,4,ICD code for underlying cause-of-death 3 digits:,Numeric
17,19,3,Cause-of-Death Recode,Numeric
20,23,4,Number of deaths,Numeric
</code></pre></div></div> <p>Then, I read the layout file:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># define names of columns</span><span class="w">
</span><span class="n">colnames</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"start"</span><span class="p">,</span><span class="w"> </span><span class="s2">"end"</span><span class="p">,</span><span class="w"> </span><span class="s2">"width"</span><span class="p">,</span><span class="w"> </span><span class="s2">"name"</span><span class="p">,</span><span class="w"> </span><span class="s2">"type"</span><span class="p">)</span><span class="w">
</span><span class="n">dict</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"data/dictMortality.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">col.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   start end width                                             name    type
## 1     1   2     2                                  FIPS State code Numeric
## 2     3   5     3                                 FIPS county code Numeric
## 3     6   9     4                                    Year of death Numeric
## 4    11  12     2                                     Age at death Numeric
## 5    13  16     4 ICD code for underlying cause-of-death 3 digits: Numeric
## 6    17  19     3                            Cause-of-Death Recode Numeric
## 7    20  23     4                                 Number of deaths Numeric</code></pre></figure> <p>Now, I can read the fixed-width data file. I use the <a href="https://github.com/hadley/readr">readr</a> package (in my experience relatively fast for big datasets ~ 1 GB).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">readr</span><span class="p">)</span><span class="w">

</span><span class="c1"># create name of variables</span><span class="w">
</span><span class="n">cnames</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"state"</span><span class="p">,</span><span class="w"> </span><span class="s2">"county"</span><span class="p">,</span><span class="w"> </span><span class="s2">"year"</span><span class="p">,</span><span class="w"> </span><span class="s2">"age"</span><span class="p">,</span><span class="w"> </span><span class="s2">"icd"</span><span class="p">,</span><span class="w"> </span><span class="s2">"cause"</span><span class="p">,</span><span class="w"> </span><span class="s2">"deaths"</span><span class="p">)</span><span class="w">

</span><span class="c1"># read mortality file</span><span class="w">
</span><span class="n">mort</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_fwf</span><span class="p">(</span><span class="s2">"data/mort7988.txt"</span><span class="p">,</span><span class="w"> </span><span class="n">fwf_positions</span><span class="p">(</span><span class="n">dict</span><span class="o">$</span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="o">$</span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">cnames</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## # A tibble: 8,776,385 x 7
##    state county  year   age   icd cause deaths
##    &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;
##  1    01    001  1979    04  5789   780      1
##  2    01    001  1979    04  7980   770      1
##  3    01    001  1979    08  8121   800      1
##  4    01    001  1979    09  3439   780      1
##  5    01    001  1979    09  8120   800      2
##  6    01    001  1979    09  8189   800      1
##  7    01    001  1979    10  1629   180      1
##  8    01    001  1979    10  2396   250      1
##  9    01    001  1979    10  4289   410      1
## 10    01    001  1979    10  8070   810      1
## # ... with 8,776,375 more rows</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># year distribution</span><span class="w">
</span><span class="n">table</span><span class="p">(</span><span class="n">mort</span><span class="o">$</span><span class="n">year</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   1979   1980   1981   1982   1983   1984   1985   1986   1987   1988
## 831605 854860 854198 850505 867280 875607 894176 905736 912551 929867</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># number of deaths</span><span class="w">
</span><span class="nf">sum</span><span class="p">(</span><span class="n">mort</span><span class="o">$</span><span class="n">deaths</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 20398153</code></pre></figure> <p>Hopefully, this might save you some time!</p> <p><strong>Last Update: 06/29/2017</strong></p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="demography"/><summary type="html"><![CDATA[Reading fixed-width text files might be challenging, specially when we don’t have a dictionary file. In this post, I show steps to read CDC files in a more systematic way. In this example, I import a compress mortality file (CMF 1979-1988) available here and whose codebook (or layout) is here.]]></summary></entry><entry><title type="html">R package to compute statistics from the American Community Survey (ACS) and Decennial US Census</title><link href="https://sdaza.com/blog/2016/acsr/" rel="alternate" type="text/html" title="R package to compute statistics from the American Community Survey (ACS) and Decennial US Census"/><published>2016-07-06T00:00:00+00:00</published><updated>2016-07-06T00:00:00+00:00</updated><id>https://sdaza.com/blog/2016/acsr</id><content type="html" xml:base="https://sdaza.com/blog/2016/acsr/"><![CDATA[<p>The <code class="language-plaintext highlighter-rouge">acsr</code> package helps extracting variables and computing statistics using the America Community Survey and Decennial US Census. It was created for the <a href="http://www.apl.wisc.edu/">Applied Population Laboratory</a> (APL) at the University of Wisconsin-Madison.</p> <h2 class="section-heading">Installation</h2> <p>The functions depend on the <code class="language-plaintext highlighter-rouge">acs</code> and <code class="language-plaintext highlighter-rouge">data.table</code> packages, so it is necessary to install then before using <code class="language-plaintext highlighter-rouge">acsr</code>. The <code class="language-plaintext highlighter-rouge">acsr</code> package is hosted on a github repository and can be installed using <code class="language-plaintext highlighter-rouge">devtools</code>:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">devtools</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s2">"sdaza/acsr"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">acsr</span><span class="p">)</span></code></pre></figure> <p>Remember to set the ACS API key, to check the help documentation and the default values of the <code class="language-plaintext highlighter-rouge">acsr</code> functions.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">api.key.install</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s2">"*"</span><span class="p">)</span><span class="w">
</span><span class="o">?</span><span class="n">sumacs</span><span class="w">
</span><span class="o">?</span><span class="n">acsdata</span></code></pre></figure> <p>The default dataset is <code class="language-plaintext highlighter-rouge">acs</code>, the level is <code class="language-plaintext highlighter-rouge">state</code> (Wisconsin, <code class="language-plaintext highlighter-rouge">state = "WI"</code>), the <code class="language-plaintext highlighter-rouge">endyear</code> is 2014, and the confidence level to compute margins of error (MOEs) is 90%.</p> <h2 class="section-heading">Levels</h2> <p>The <code class="language-plaintext highlighter-rouge">acsr</code> functions can extract all the levels available in the <code class="language-plaintext highlighter-rouge">acs</code> package. The table below shows the summary and required levels when using the <code class="language-plaintext highlighter-rouge">acsdata</code> and <code class="language-plaintext highlighter-rouge">sumacs</code> functions:</p> <table> <thead> <tr> <th>summary number</th> <th>levels</th> </tr> </thead> <tbody> <tr> <td>010</td> <td>us</td> </tr> <tr> <td>020</td> <td>region</td> </tr> <tr> <td>030</td> <td>division</td> </tr> <tr> <td>040</td> <td>state</td> </tr> <tr> <td>050</td> <td>state, county</td> </tr> <tr> <td>060</td> <td>state, county, county.subdivision</td> </tr> <tr> <td>140</td> <td>state, county, tract</td> </tr> <tr> <td>150</td> <td>state, county, tract, block.group</td> </tr> <tr> <td>160</td> <td>state, place</td> </tr> <tr> <td>250</td> <td>american.indian.area</td> </tr> <tr> <td>320</td> <td>state, msa</td> </tr> <tr> <td>340</td> <td>state, csa</td> </tr> <tr> <td>350</td> <td>necta</td> </tr> <tr> <td>400</td> <td>urban.area</td> </tr> <tr> <td>500</td> <td>state, congressional.district</td> </tr> <tr> <td>610</td> <td>state, state.legislative.district.upper</td> </tr> <tr> <td>620</td> <td>state, state.legislative.district.lower</td> </tr> <tr> <td>795</td> <td>state, puma</td> </tr> <tr> <td>860</td> <td>zip.code</td> </tr> <tr> <td>950</td> <td>state, school.district.elementary</td> </tr> <tr> <td>960</td> <td>state, school.district.secondary</td> </tr> <tr> <td>970</td> <td>state, school.district.unified</td> </tr> </tbody> </table> <h2 class="section-heading">Getting variables and statistics</h2> <p>We can use the <code class="language-plaintext highlighter-rouge">sumacs</code> function to extract variable and statistics. We have to specify the corresponding method (e.g., <em>proportion</em> or just <em>variable</em>), and the name of the statistic or variable to be included in the output.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w"> </span><span class="s2">"b16004_026"</span><span class="p">),</span><span class="w">
        </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myvar"</span><span class="p">),</span><span class="w">
        </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"prop"</span><span class="p">,</span><span class="w"> </span><span class="s2">"variable"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"division"</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel geoid division mynewvar_est mynewvar_moe myvar_est myvar_moe
## 1:      030    NA        1       0.0762     0.000347    770306      3490
## 2:      030    NA        2       0.1182     0.000278   3332150      9171
## 3:      030    NA        3       0.0599     0.000196   1819417      7209
## 4:      030    NA        4       0.0411     0.000277    547577      4461
## 5:      030    NA        5       0.1108     0.000246   4526480     11869
## 6:      030    NA        6       0.0320     0.000265    402475      3781
## 7:      030    NA        7       0.2203     0.000469   5318126     13044
## 8:      030    NA        8       0.1582     0.000602   2279303     10746
## 9:      030    NA        9       0.2335     0.000501   7765838     20289</code></pre></figure> <p>To download the data can be slow, especially when many levels are being used (e.g., blockgroup). A better approach in those cases is, first, download the data using the function <code class="language-plaintext highlighter-rouge">acsdata</code> , and then use them as input.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">mydata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">acsdata</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 /  b16004_001)"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"b16004_026"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"division"</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] ". . . . . .  Getting division data"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w"> </span><span class="s2">"b16004_026"</span><span class="p">),</span><span class="w">
        </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myvar"</span><span class="p">),</span><span class="w">
        </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"prop"</span><span class="p">,</span><span class="w"> </span><span class="s2">"variable"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"division"</span><span class="p">),</span><span class="w">
        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mydata</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel geoid division mynewvar_est mynewvar_moe myvar_est myvar_moe
## 1:      030    NA        1       0.0762     0.000347    770306      3490
## 2:      030    NA        2       0.1182     0.000278   3332150      9171
## 3:      030    NA        3       0.0599     0.000196   1819417      7209
## 4:      030    NA        4       0.0411     0.000277    547577      4461
## 5:      030    NA        5       0.1108     0.000246   4526480     11869
## 6:      030    NA        6       0.0320     0.000265    402475      3781
## 7:      030    NA        7       0.2203     0.000469   5318126     13044
## 8:      030    NA        8       0.1582     0.000602   2279303     10746
## 9:      030    NA        9       0.2335     0.000501   7765838     20289</code></pre></figure> <h2 class="section-heading">Standard errors</h2> <p>When computing statistics there are two ways to define the standard errors:</p> <ul> <li>Including all standard errors of the variables used to compute a statistic (<code class="language-plaintext highlighter-rouge">one.zero = FALSE</code>)</li> <li>Include all standard errors except those of variables that are equal to zero. Only the maximum standard error of the variables equal to zero is included (<code class="language-plaintext highlighter-rouge">one.zero = TRUE</code>)</li> <li>The default value is <code class="language-plaintext highlighter-rouge">one.zero = TRUE</code></li> </ul> <p>For more details about how standard errors are computed for proportions, ratios and aggregations look at <a href="https://www.census.gov/content/dam/Census/library/publications/2008/acs/ACSGeneralHandbook.pdf">A Compass for Understanding and Using American Community Survey Data</a>.</p> <p>Below an example when estimating proportions and using <code class="language-plaintext highlighter-rouge">one.zero = FALSE</code>:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048) / b16004_001"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tract"</span><span class="p">,</span><span class="w">
            </span><span class="n">county</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">
            </span><span class="n">tract</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">950501</span><span class="p">,</span><span class="w">
            </span><span class="n">endyear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2013</span><span class="p">,</span><span class="w">
            </span><span class="n">one.zero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2013"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting tract data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel       geoid st_fips cnty_fips tract_fips mynewvar_est mynewvar_moe
## 1:      140 55001950501      55         1     950501       0.0226       0.0252</code></pre></figure> \[SE = \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2 + 5.47 ^ 2) - ( 0.02 ^ 2 \times 102.13 ^ 2)}{1546} } \times 1.645 = 0.0252\] <p>When <code class="language-plaintext highlighter-rouge">one.zero = TRUE</code>:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048) / b16004_001"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tract"</span><span class="p">,</span><span class="w">
            </span><span class="n">county</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">
            </span><span class="n">tract</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">950501</span><span class="p">,</span><span class="w">
            </span><span class="n">endyear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2013</span><span class="p">,</span><span class="w">
            </span><span class="n">one.zero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2013"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting tract data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel       geoid st_fips cnty_fips tract_fips mynewvar_est mynewvar_moe
## 1:      140 55001950501      55         1     950501       0.0226       0.0245</code></pre></figure> \[SE_{\text{ one.zero}} \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2) - ( 0.02 ^ 2 \times 102.13 ^ 2)}{1546} } \times 1.645 = 0.0245\] <p>When the square root value in the standard error formula doesn’t exist (e.g., the square root of a negative number), the ratio formula is instead used. The ratio adjustment is done <strong>variable by variable</strong> .</p> <p>It can also be that the <code class="language-plaintext highlighter-rouge">one.zero</code> option makes the square root undefinable. In those cases, the function uses again the <strong>ratio</strong> formula to compute standard errors. There is also a possibility that the standard error estimates using the <strong>ratio</strong> formula are higher than the <strong>proportion</strong> estimates without the <code class="language-plaintext highlighter-rouge">one.zero</code> option.</p> <h2 class="section-heading">Decennial Data from the US Census</h2> <p>Let’s get the African American and Hispanic population by state. In this case, we don’t have any estimation of margin of error.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"p0080004"</span><span class="p">,</span><span class="w"> </span><span class="s2">"p0090002"</span><span class="p">),</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"variable"</span><span class="p">,</span><span class="w">
            </span><span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"sf1"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"state"</span><span class="p">,</span><span class="w">
            </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"*"</span><span class="p">,</span><span class="w">
            </span><span class="n">endyear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2010</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: sf1 2010"
## [1] ". . . . . .  ACS/Census variables : 2"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Getting state data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     sumlevel geoid st_fips p0080004 p0090002
##  1:      040    01      01  1251311   185602
##  2:      040    02      02    23263    39249
##  3:      040    04      04   259008  1895149
##  4:      040    05      05   449895   186050
##  5:      040    06      06  2299072 14013719
##  6:      040    08      08   201737  1038687
##  7:      040    09      09   362296   479087
##  8:      040    10      10   191814    73221
##  9:      040    11      11   305125    54749
## 10:      040    12      12  2999862  4223806
## 11:      040    13      13  2950435   853689
## 12:      040    15      15    21424   120842
## 13:      040    16      16     9810   175901
## 14:      040    17      17  1866414  2027578
## 15:      040    18      18   591397   389707
## 16:      040    19      19    89148   151544
## 17:      040    20      20   167864   300042
## 18:      040    21      21   337520   132836
## 19:      040    22      22  1452396   192560
## 20:      040    23      23    15707    16935
## 21:      040    24      24  1700298   470632
## 22:      040    25      25   434398   627654
## 23:      040    26      26  1400362   436358
## 24:      040    27      27   274412   250258
## 25:      040    28      28  1098385    81481
## 26:      040    29      29   693391   212470
## 27:      040    30      30     4027    28565
## 28:      040    31      31    82885   167405
## 29:      040    32      32   218626   716501
## 30:      040    33      33    15035    36704
## 31:      040    34      34  1204826  1555144
## 32:      040    35      35    42550   953403
## 33:      040    36      36  3073800  3416922
## 34:      040    37      37  2048628   800120
## 35:      040    38      38     7960    13467
## 36:      040    39      39  1407681   354674
## 37:      040    40      40   277644   332007
## 38:      040    41      41    69206   450062
## 39:      040    42      42  1377689   719660
## 40:      040    44      44    60189   130655
## 41:      040    45      45  1290684   235682
## 42:      040    46      46    10207    22119
## 43:      040    47      47  1057315   290059
## 44:      040    48      48  2979598  9460921
## 45:      040    49      49    29287   358340
## 46:      040    50      50     6277     9208
## 47:      040    51      51  1551399   631825
## 48:      040    53      53   240042   755790
## 49:      040    54      54    63124    22268
## 50:      040    55      55   359148   336056
## 51:      040    56      56     4748    50231
## 52:      040    72      72   461498  3688455
##     sumlevel geoid st_fips p0080004 p0090002</code></pre></figure> <h2 class="section-heading">Output</h2> <p>The output can be formatted using a wide or long format:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"division"</span><span class="p">,</span><span class="w">
            </span><span class="n">format.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"long"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    geoid sumlevel division var_name    est      moe
## 1:    NA      030        1 mynewvar 0.0762 0.000347
## 2:    NA      030        2 mynewvar 0.1182 0.000278
## 3:    NA      030        3 mynewvar 0.0599 0.000196
## 4:    NA      030        4 mynewvar 0.0411 0.000277
## 5:    NA      030        5 mynewvar 0.1108 0.000246
## 6:    NA      030        6 mynewvar 0.0320 0.000265
## 7:    NA      030        7 mynewvar 0.2203 0.000469
## 8:    NA      030        8 mynewvar 0.1582 0.000602
## 9:    NA      030        9 mynewvar 0.2335 0.000501</code></pre></figure> <p>And it can also be exported to a csv file:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"division"</span><span class="p">,</span><span class="w">
            </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"myfile.out"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] "Data exported to a CSV file! "</code></pre></figure> <h2 class="section-heading">Combining geographic levels</h2> <p>We can combine geographic levels using two methods: (1) <code class="language-plaintext highlighter-rouge">sumacs</code> and (2) <code class="language-plaintext highlighter-rouge">combine.output</code>. The first one allows only single combinations, the second multiple ones.</p> <p>If I want to combine two states (e.g., Wisconsin and Minnesota) I can use:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
    </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
    </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
    </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"state"</span><span class="p">,</span><span class="w">
    </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"WI"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MN"</span><span class="p">),</span><span class="w">
    </span><span class="n">combine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
    </span><span class="n">print.levels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting combined data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    geoid combined_group mynewvar_est mynewvar_moe
## 1:    NA      aggregate        0.042     0.000331</code></pre></figure> <p>If I want to put together multiple combinations (e.g., groups of states):</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">combine.output</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
    </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
    </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
    </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"state"</span><span class="p">,</span><span class="w"> </span><span class="s2">"state"</span><span class="p">),</span><span class="w">
    </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"WI"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MN"</span><span class="p">),</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"CA"</span><span class="p">,</span><span class="w"> </span><span class="s2">"OR"</span><span class="p">)),</span><span class="w"> </span><span class="c1"># nested list</span><span class="w">
    </span><span class="n">combine.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"WI+MN"</span><span class="p">,</span><span class="w"> </span><span class="s2">"CA+OR"</span><span class="p">),</span><span class="w">
    </span><span class="n">print.levels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] ". . . . . .  Defining WI+MN"
## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting combined data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Defining CA+OR"
## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting combined data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    combined_group mynewvar_est mynewvar_moe
## 1:          WI+MN        0.042     0.000331
## 2:          CA+OR        0.269     0.000565</code></pre></figure> <h2 class="section-heading">A map?</h2> <p>Let’s color a map using poverty by county:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">pov</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"b17001_002 / b17001_001 * 100"</span><span class="p">,</span><span class="w">
        </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"pov"</span><span class="p">),</span><span class="w">
        </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"prop"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"county"</span><span class="p">),</span><span class="w">
        </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"*"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 2"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting county data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">choroplethr</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">choroplethrMaps</span><span class="p">)</span><span class="w">
</span><span class="n">pov</span><span class="p">[,</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">geoid</span><span class="p">)]</span><span class="w">
</span><span class="n">setnames</span><span class="p">(</span><span class="n">pov</span><span class="p">,</span><span class="w"> </span><span class="s2">"pov_est"</span><span class="p">,</span><span class="w"> </span><span class="s2">"value"</span><span class="p">)</span><span class="w">
</span><span class="n">county_choropleth</span><span class="p">(</span><span class="n">pov</span><span class="p">,</span><span class="w"> </span><span class="n">num_colors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2016-07-06-acsr/unnamed-chunk-15-1.png" alt="center"/></p> <p>In sum, the <code class="language-plaintext highlighter-rouge">acsr</code> package:</p> <ul> <li>Reads formulas directly and extracts any ACS/Census variable</li> <li>Provides an automatized and tailored way to obtain indicators and MOEs</li> <li>Allows different outputs’ formats (wide and long, csv)</li> <li>Provides an easy way to adjust MOEs to different confidence levels</li> <li>Includes a variable-by-variable ratio adjustment of standard errors</li> <li>Includes the zero-option when computing standard errors for proportions, ratios, and aggregations</li> <li>Combines geographic levels flexibly</li> </ul> <p><strong>Last Update: 02/07/2016</strong></p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="demography"/><category term="data science"/><summary type="html"><![CDATA[The acsr package helps extracting variables and computing statistics using the America Community Survey and Decennial US Census. It was created for the Applied Population Laboratory (APL) at the University of Wisconsin-Madison.]]></summary></entry><entry><title type="html">Imputing scales using parcels of items as auxiliary variables</title><link href="https://sdaza.com/blog/2015/imputation-parcels/" rel="alternate" type="text/html" title="Imputing scales using parcels of items as auxiliary variables"/><published>2015-10-14T00:00:00+00:00</published><updated>2015-10-14T00:00:00+00:00</updated><id>https://sdaza.com/blog/2015/imputation-parcels</id><content type="html" xml:base="https://sdaza.com/blog/2015/imputation-parcels/"><![CDATA[<p>Multiple imputation of scales generated by several items can be challenging. Fortunately, to impute every single item is not the only solution to the missing data problem. Some practical and <em>theoretically</em> attractive alternative have already been proposed. In this post, I show a simple implementation of what Enders (2010) calls <strong>duplicated-scale imputation</strong>, a method orginally suggested by Eekhout et al. (2011). By the way, thanks <a href="http://www.iriseekhout.com">Iris Eekhout</a> for replying my e-mails!</p> <h2 id="procedure">Procedure</h2> <p>For each scale, I define a number or proportion of items (let’s say <strong>p</strong>) to create parcels (i.e., average of items although not the whole scale). These parcels are, then, used as auxiliary variables to <em>impute</em> the original scales. There are different ways to define parcels. I implemented a solution in my R package <a href="http://github.com/sdaza/sdazar">sdazar</a>, see the function <code class="language-plaintext highlighter-rouge">rowscore</code> for more details.</p> <p>The function <code class="language-plaintext highlighter-rouge">rowscore</code> selects <strong>p</strong> items with the least missing data. For each case (row), it computes the parcels using the available information of the selected items. If only one item has information, only that one will be used. If there are more than one item with valid data, it will average all the selected items. If there are no items available in my initial selection, it picks <strong>p</strong> items from the rest of unselected items to impute the original scale. In this particular example, I create parcels using half of the items:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">rowscore</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">items</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"parcel"</span><span class="p">)</span></code></pre></figure> <p>The reason for using a proportion of the original items is to include as much information as possible, but preventing strong linear dependencies between variables. Ideally, parcels are complete (no missing values). However, in some cases all the items are missing, so parcels can still have missing records (although less than the original scales).</p> <p><strong>Why not just to use the average of the available items?</strong> That solution would implicitly assume that items perfectly correlate with the scale. We know that’s not a good assumption. That is why we worry about creating scales in the first place, right? Using parcels takes advantage of the available information (items with complete information) and the relationship between a portion of items and the scale.</p> <p>Here I show a simple example using the <a href="http://www.cpc.unc.edu/projects/addhealth">National Longitudinal Study of Adolescent to Adult Health (Add Health)</a>. First, let’s look some descriptives of the variables included in the imputation. I am using information from Wave 1 and 2. The scales/scores I am imputing are depression (19 items) and GPA (4 items). Variables ending with <code class="language-plaintext highlighter-rouge">.p</code> are parcels with 1/2 of the items of the original scale.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="nf">dim</span><span class="p">(</span><span class="n">dats</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 12976    14</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">str</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">nvars</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">])</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## Classes 'data.table' and 'data.frame':	12976 obs. of  14 variables:
##  $ female   : Factor w/ 2 levels "0","1": 1 1 1 2 1 1 1 1 1 1 ...
##  $ age      : int  16 16 14 13 14 17 14 17 17 14 ...
##  $ race     : Factor w/ 5 levels "white","black",..: 2 1 1 1 2 1 3 3 3 2 ...
##  $ publicass: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 NA ...
##  $ bmi      : num  27.4 16.3 22.2 18.2 21.9 ...
##  $ gpa1     : num  2 3.25 3.75 3.25 2.25 1 NA 2.25 NA 2.5 ...
##  $ gpa2     : num  2.5 2.5 4 3.75 1.75 1.5 NA 3 1 4 ...
##  $ gpa1.p   : num  2.5 3.5 3.5 3 2.5 1 3.5 3 1 3.5 ...
##  $ gpa2.p   : num  2.5 2.5 4 3.5 1.5 2 1.5 3 1 4 ...
##  $ dep1.p   : num  0.2 0.7 0 0.3 0.4 0.4 0.1 1 0.6 1.2 ...
##  $ dep1     : num  0.263 0.789 0 0.211 0.474 ...
##  $ dep2.p   : num  0.6 0.6 0.1 0.3 0.4 0.6 0.2 1.1 0.8 0.5 ...
##  $ dep2     : num  0.6316 0.5263 0.0526 0.1579 0.3684 ...
##  $ ppvt     : int  101 75 121 96 79 97 103 89 82 120 ...
##  - attr(*, ".internal.selfref")=&lt;externalptr&gt;</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create summary table using package tables</span><span class="w">
</span><span class="n">missing</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="nf">sum</span><span class="p">(</span><span class="nf">is.na</span><span class="p">(</span><span class="n">x</span><span class="p">))}</span><span class="w">
</span><span class="n">tabular</span><span class="p">(</span><span class="w">
  </span><span class="p">(</span><span class="w"> </span><span class="n">dep2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep2.p</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1.p</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2.p</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">gpa1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa1.p</span><span class="w">  </span><span class="o">+</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">bmi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ppvt</span><span class="w"> </span><span class="p">)</span><span class="w">
   </span><span class="o">~</span><span class="w">  </span><span class="p">(</span><span class="n">Format</span><span class="p">(</span><span class="n">digit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Mean"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Mean</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"SD"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Sd</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Min"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Min</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Max"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Max</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Missing"</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">missing</span><span class="w"> </span><span class="p">))),</span><span class="w">
  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dats</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##
##         Mean    SD      Min     Max     Missing
##  dep2      0.58    0.39    0.00    2.95   68.00
##  dep2.p    0.58    0.43    0.00    3.00    6.00
##  dep1      0.58    0.39    0.00    2.84   81.00
##  dep1.p    0.62    0.44    0.00    3.00   18.00
##  gpa2      2.86    0.74    1.00    4.00 4710.00
##  gpa2.p    2.76    0.84    1.00    4.00 1238.00
##  gpa1      2.82    0.76    1.00    4.00 2788.00
##  gpa1.p    2.74    0.85    1.00    4.00  342.00
##  age      15.28    1.61   11.00   21.00    9.00
##  bmi      22.37    4.42   11.47   63.47  353.00
##  ppvt    100.17   15.00   13.00  146.00  568.00</code></pre></figure> <p>As expected, the correlation between the scales and parcels is high. GPA has most of the problems. Note that parcels <code class="language-plaintext highlighter-rouge">.p</code> still have missing records, although much less than the original scales.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">dep1</span><span class="p">,</span><span class="w"> </span><span class="n">dep1.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         dep1 dep1.p
## dep1   1.000  0.947
## dep1.p 0.947  1.000</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">dep2</span><span class="p">,</span><span class="w"> </span><span class="n">dep2.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         dep2 dep2.p
## dep2   1.000  0.948
## dep2.p 0.948  1.000</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">gpa1</span><span class="p">,</span><span class="w"> </span><span class="n">gpa1.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         gpa1 gpa1.p
## gpa1   1.000  0.888
## gpa1.p 0.888  1.000</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">gpa2</span><span class="p">,</span><span class="w"> </span><span class="n">gpa2.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         gpa2 gpa2.p
## gpa2   1.000  0.885
## gpa2.p 0.885  1.000</code></pre></figure> <p>Let’s now impute the scales/scores using the R package <em>MICE</em>.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ini</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mice</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">nvars</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">],</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">maxit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">

</span><span class="c1"># get methods</span><span class="w">
</span><span class="p">(</span><span class="n">meth</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ini</span><span class="o">$</span><span class="n">meth</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    female       age      race publicass       bmi      gpa1      gpa2    gpa1.p    gpa2.p    dep1.p      dep1    dep2.p      dep2      ppvt
##        ""     "pmm"        ""  "logreg"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># get predictor matrix</span><span class="w">
</span><span class="n">pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ini</span><span class="o">$</span><span class="n">pred</span></code></pre></figure> <p>I adjust the predictor matrix to avoid feedbacks during the imputation (circularity between variables). The trick is to use only complete variables when imputing <em>parcels</em>.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># predict parcels only with complete variables to avoid feedbacks</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa1.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa2.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep1.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep2.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">

</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa1.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa2.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep1.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep2.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">

</span><span class="c1"># predict scales using parcels</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"gpa1.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"gpa2.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"dep1.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"dep2.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">

</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa1"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"gpa1.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa2"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"gpa2.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep1"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"dep1.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep2"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"dep2.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span></code></pre></figure> <p>Here the adjusted predictor matrix:</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">##           female age race publicass bmi gpa1 gpa2 gpa1.p gpa2.p dep1.p dep1 dep2.p dep2 ppvt
## female         0   0    0         0   0    0    0      0      0      0    0      0    0    0
## age            1   0    1         1   1    1    1      0      0      0    1      0    1    1
## race           0   0    0         0   0    0    0      0      0      0    0      0    0    0
## publicass      1   1    1         0   1    1    1      0      0      0    1      0    1    1
## bmi            1   1    1         1   0    1    1      0      0      0    1      0    1    1
## gpa1           1   1    1         1   1    0    1      1      0      0    1      0    1    1
## gpa2           1   1    1         1   1    1    0      0      1      0    1      0    1    1
## gpa1.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## gpa2.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## dep1.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## dep1           1   1    1         1   1    1    1      0      0      1    0      0    1    1
## dep2.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## dep2           1   1    1         1   1    1    1      0      0      0    1      1    0    1
## ppvt           1   1    1         1   1    1    1      0      0      0    1      0    1    0</code></pre></figure> <p>Let’s impute the data!</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">imp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mice</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">nvars</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">],</span><span class="w"> </span><span class="n">pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">maxit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span></code></pre></figure> <p>Below some plots to explore how the imputation goes.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">plot</span><span class="p">(</span><span class="n">imp</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"gpa1"</span><span class="p">,</span><span class="w"> </span><span class="s2">"gpa2"</span><span class="p">,</span><span class="w"> </span><span class="s2">"dep1"</span><span class="p">,</span><span class="w"> </span><span class="s2">"dep2"</span><span class="p">))</span></code></pre></figure> <p><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-12-1.png" alt="center"/><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-12-2.png" alt="center"/></p> <p>I don’t see any problematic pattern. It seems I get a proper solution. The distribution of the variables also looks right.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">densityplot</span><span class="p">(</span><span class="n">imp</span><span class="p">,</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">gpa1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep2</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-13-1.png" alt="center"/></p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">bwplot</span><span class="p">(</span><span class="n">imp</span><span class="p">,</span><span class="w"> </span><span class="n">gpa1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep2</span><span class="w">  </span><span class="o">~</span><span class="w"> </span><span class="n">.imp</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-13-2.png" alt="center"/></p> <p><strong>Last Update: 06/02/2017</strong></p> <hr/> <h3 id="references">References</h3> <p>Enders, Craig K. 2010. <em>Applied Missing Data Analysis</em>. The Guilford Press.</p> <p>Eekhout, Iris, Craig K. Enders, Jos W. R. Twisk, Michiel R. de Boer, Henrica C. W. de Vet, and Martijn W. Heymans. 2015. “Analyzing Incomplete Item Scores in Longitudinal Data by Including Item Score Information as Auxiliary Variables.” <em>Structural Equation Modeling: A Multidisciplinary Journal</em> 22 (4):588-602.</p>]]></content><author><name>Sebastian Daza</name></author><category term="data science"/><category term="R"/><summary type="html"><![CDATA[Multiple imputation of scales generated by several items can be challenging. Fortunately, to impute every single item is not the only solution to the missing data problem. Some practical and theoretically attractive alternative have already been proposed. In this post, I show a simple implementation of what Enders (2010) calls duplicated-scale imputation, a method orginally suggested by Eekhout et al. (2011). By the way, thanks Iris Eekhout for replying my e-mails!]]></summary></entry><entry><title type="html">Simple R package to define sample sizes and MOEs</title><link href="https://sdaza.com/blog/2015/sampler/" rel="alternate" type="text/html" title="Simple R package to define sample sizes and MOEs"/><published>2015-09-30T00:00:00+00:00</published><updated>2015-09-30T00:00:00+00:00</updated><id>https://sdaza.com/blog/2015/sampler</id><content type="html" xml:base="https://sdaza.com/blog/2015/sampler/"><![CDATA[<p>I present a simple R package called <a href="https://github.com/sdaza/sampler"><strong>sampler</strong></a>. The package defines <strong>sample sizes</strong> and <strong>margins of error (MOE)</strong> for proportions, as usually it is needed when designing public opinion surveys. <a href="/survey/2014/01/19/samplesize/">In a previous post</a>, I showed some functions that do mostly the same thing. This new package, though, includes some new features that can be useful when allocating a sample.</p> <h2 id="installation">Installation</h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># you have to install devtools first</span><span class="w">
</span><span class="n">devtools</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s2">"sdaza/sampler"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span></code></pre></figure> <h2 id="functions">Functions</h2> <p>The packages contains four functions:</p> <ul> <li><strong>ssize</strong>: computes sample size.</li> <li><strong>serr</strong>: computes MOE.</li> <li><strong>astrata</strong>: assigns sample sizes to strata.</li> <li><strong>serrst</strong>: computes MOE for stratified samples.</li> </ul> <h2 id="define-sample-size-ssize">Define sample size: <em>ssize</em></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 384</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># design effect (deff) and response rate (rr)</span><span class="w">
</span><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 512</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># finite population correction</span><span class="w">
</span><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 370</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># warning message</span><span class="w">
</span><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## n is bigger than N in some rows: n = N</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 100</code></pre></figure> <h2 id="define-sampling-error-serr">Define sampling error: <em>serr</em></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">384</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.05</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">512</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.05</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">370</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.05</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># we still get an answer</span><span class="w">
</span><span class="n">serr</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0569</code></pre></figure> <h2 id="strata-allocation-astrata">Strata allocation: <em>astrata</em></h2> <p>These examples show how to allocate a sample size into strata. Look at <em>?astrata</em> in <strong>R</strong> for definitions of the allocation procedures that are available.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># I will use data.table</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span><span class="w">
</span><span class="n">chile</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="n">chile</span><span class="p">)</span><span class="w">
</span><span class="n">chile</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr
##  1:   1  328782 0.3
##  2:   2  613328 0.4
##  3:   3  308247 0.5
##  4:   4  759228 0.5
##  5:   5 1808300 0.5
##  6:   6  910577 0.6
##  7:   7 1035593 0.3
##  8:   8 2100494 0.1
##  9:   9  983499 0.2
## 10:  10  834714 0.5
## 11:  11  107334 0.5
## 12:  12  163748 0.4
## 13:  13 7228581 0.6
## 14:  14  401548 0.2
## 15:  15  235081 0.3</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># proportional for a sample of 1000</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aprop</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># fixed (same number by stratum)</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">afixed</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># 40% proportional, 60% fixed</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">a40</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="m">.4</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># 60% proportional, 40% fixed</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">a60</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="m">.6</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># square-root</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aroot</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"root"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># neyman</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aneyman</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"neyman"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># standard deviation</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">astdev</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"stdev"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># error</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aerr</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.11</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"error"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr aprop afixed a40 a60 aroot aneyman astdev aerr
##  1:   1  328782 0.3    18     67  47  38    41      18     66   67
##  2:   2  613328 0.4    34     67  54  47    56      37     71   76
##  3:   3  308247 0.5    17     67  47  37    40      19     72   79
##  4:   4  759228 0.5    43     67  57  53    62      46     72   79
##  5:   5 1808300 0.5   101     67  81  87    96     110     72   79
##  6:   6  910577 0.6    51     67  61  57    68      54     71   76
##  7:   7 1035593 0.3    58     67  63  62    73      58     66   67
##  8:   8 2100494 0.1   118     67  87  98   104      77     43   29
##  9:   9  983499 0.2    55     67  62  60    71      48     58   51
## 10:  10  834714 0.5    47     67  59  55    65      51     72   79
## 11:  11  107334 0.5     6     67  43  30    23       7     72   79
## 12:  12  163748 0.4     9     67  44  32    29      10     71   76
## 13:  13 7228581 0.6   406     67 203 270   192     432     71   76
## 14:  14  401548 0.2    23     67  49  41    45      20     58   51
## 15:  15  235081 0.3    13     67  45  35    35      13     66   67</code></pre></figure> <h2 id="getting-sampling-error-from-a-stratified-sample-serrst">Getting sampling error from a stratified sample: <em>serrst</em></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the second most efficient allocation</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aprop</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0288</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the worst solution</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">afixed</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0518</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">a40</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0339</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">a60</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0311</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aroot</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0339</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the most efficient allocation</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aneyman</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0285</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">astdev</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0508</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aerr</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0498</code></pre></figure> <h2 id="combining-criteria">Combining criteria</h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># get error for 60% proportional / 40% fixed allocation for each strata</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">error_a60</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">serr</span><span class="p">(</span><span class="n">a60</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># assign sample sizes assuming 13% error for each strata</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">serr13</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.13</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"error"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># total error, not that good!</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">serr13</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0586</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">pr</span><span class="p">,</span><span class="w"> </span><span class="n">a60</span><span class="p">,</span><span class="w"> </span><span class="n">error_a60</span><span class="p">,</span><span class="w"> </span><span class="n">serr13</span><span class="p">)]</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr a60 error_a60 serr13
##  1:   1  328782 0.3  38    0.1457     48
##  2:   2  613328 0.4  47    0.1401     55
##  3:   3  308247 0.5  37    0.1611     57
##  4:   4  759228 0.5  53    0.1346     57
##  5:   5 1808300 0.5  87    0.1051     57
##  6:   6  910577 0.6  57    0.1272     55
##  7:   7 1035593 0.3  62    0.1141     48
##  8:   8 2100494 0.1  98    0.0594     20
##  9:   9  983499 0.2  60    0.1012     36
## 10:  10  834714 0.5  55    0.1321     57
## 11:  11  107334 0.5  30    0.1789     57
## 12:  12  163748 0.4  32    0.1697     55
## 13:  13 7228581 0.6 270    0.0584     55
## 14:  14  401548 0.2  41    0.1224     36
## 15:  15  235081 0.3  35    0.1518     48</code></pre></figure> <p>We can adjust a bit more:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># when error is higher than .13, use serr13</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">sfinal</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">error_a60</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">.13</span><span class="p">,</span><span class="w"> </span><span class="n">serr13</span><span class="p">,</span><span class="w"> </span><span class="n">a60</span><span class="p">)]</span><span class="w">

</span><span class="c1"># new error by stratum</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">error_sfinal</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">serr</span><span class="p">(</span><span class="n">sfinal</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># total error, much better!</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">sfinal</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0309</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># although the total sample size is now bigger</span><span class="w">
</span><span class="nf">sum</span><span class="p">(</span><span class="n">chile</span><span class="o">$</span><span class="n">sfinal</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1109</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr sfinal error_sfinal
##  1:   1  328782 0.3     48       0.1296
##  2:   2  613328 0.4     55       0.1295
##  3:   3  308247 0.5     57       0.1298
##  4:   4  759228 0.5     57       0.1298
##  5:   5 1808300 0.5     87       0.1051
##  6:   6  910577 0.6     57       0.1272
##  7:   7 1035593 0.3     62       0.1141
##  8:   8 2100494 0.1     98       0.0594
##  9:   9  983499 0.2     60       0.1012
## 10:  10  834714 0.5     57       0.1298
## 11:  11  107334 0.5     57       0.1298
## 12:  12  163748 0.4     55       0.1295
## 13:  13 7228581 0.6    270       0.0584
## 14:  14  401548 0.2     41       0.1224
## 15:  15  235081 0.3     48       0.1296</code></pre></figure> <p>That’s it. A simple package to do simple calculations.</p>]]></content><author><name>Sebastian Daza</name></author><category term="survey"/><category term="R"/><summary type="html"><![CDATA[I present a simple R package called sampler. The package defines sample sizes and margins of error (MOE) for proportions, as usually it is needed when designing public opinion surveys. In a previous post, I showed some functions that do mostly the same thing. This new package, though, includes some new features that can be useful when allocating a sample.]]></summary></entry><entry><title type="html">Functions for sample size and error</title><link href="https://sdaza.com/blog/2014/samplesize/" rel="alternate" type="text/html" title="Functions for sample size and error"/><published>2014-01-19T00:00:00+00:00</published><updated>2014-01-19T00:00:00+00:00</updated><id>https://sdaza.com/blog/2014/samplesize</id><content type="html" xml:base="https://sdaza.com/blog/2014/samplesize/"><![CDATA[<p>Here I show two functions in R to define sample sizes and errors of a proportion, taking into account design effect, response rate, finite population correction, and stratification. They are useful when one needs to do these calculations quickly.</p> <p><strong>Note: I created a package with similar functions. <a href="/survey/2015/09/30/sampler/">See here</a>.</strong></p> <p>The inputs are:</p> <ul> <li><strong>n</strong> = sample size</li> <li><strong>e</strong> = sampling error</li> <li><strong>deff</strong> = design effect, by default 1 (SRS)</li> <li><strong>rr</strong> = response rate, by default 1</li> <li><strong>N</strong> = population size, by default NULL (infinite population)</li> <li><strong>cl</strong> = confidence level , by default .95</li> <li><strong>p</strong> = proportion, by default 0.5 (maximum variance of a proportion)</li> <li><strong>relative</strong> = to estimate relative error, by default FALSE</li> </ul> <h2 id="first-load-the-functions">first, load the functions</h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">devtools</span><span class="p">);</span><span class="w"> </span><span class="n">source_gist</span><span class="p">(</span><span class="s2">"7896840"</span><span class="p">)</span></code></pre></figure> <h2 id="serr-sampling-error">serr: sampling error</h2> <p>An example for n = 400 and all inputs at their default values:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">400</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.049</code></pre></figure> <p>The output is rounded to 4 decimals. A more complete example:</p> <ul> <li><strong>n</strong> = 400</li> <li><strong>deff</strong> = 1.5</li> <li><strong>response rate</strong> = 80%</li> <li><strong>population size</strong> = 1000</li> </ul> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">400</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0595</code></pre></figure> <p>The sample size (n) has always to be lower than the population (N). It is important to note that the final sample size used to compute the sampling error is:</p> \[n = \frac{N}{deff} * rr\] <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">400</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">350</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## Error: n is bigger than N</code></pre></figure> <h2 id="ssize-sample-size">ssize: sample size</h2> <p>Let’s get a sample size with an error of .03, a population of 1000 elements, a response rate of 0.80, and an effect design of 1.2:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ssize</span><span class="p">(</span><span class="n">e</span><span class="o">=</span><span class="m">.03</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 775</code></pre></figure> <p>If the the sample size is bigger than the population because of low response rates or big design effects, the sample size will be fixed to N:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ssize</span><span class="p">(</span><span class="n">e</span><span class="o">=</span><span class="m">.03</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="m">.6</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## n is bigger than N in some rows: n = N</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1000</code></pre></figure> <h2 id="working-with-strata">Working with strata</h2> <p>Finally, we can estimate different sample sizes by strata using vectors or a data frame:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># example sampling frame (4 strata)</span><span class="w">
</span><span class="n">frame</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
	</span><span class="n">strata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w">
	</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="m">5000</span><span class="p">,</span><span class="w"> </span><span class="m">2000</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">),</span><span class="w">
	</span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="m">.8</span><span class="p">),</span><span class="w">
	</span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="m">.9</span><span class="p">,</span><span class="w"> </span><span class="m">.85</span><span class="p">,</span><span class="m">.8</span><span class="p">),</span><span class="w">
	</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">.3</span><span class="p">,</span><span class="w"> </span><span class="m">.6</span><span class="p">,</span><span class="w"> </span><span class="m">.1</span><span class="p">,</span><span class="w"> </span><span class="m">.2</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   strata     N deff   rr   p
## 1      1 10000  1.1 0.80 0.3
## 2      2  5000  1.0 0.90 0.6
## 3      3  2000  1.3 0.85 0.1
## 4      4  1000  0.8 0.80 0.2</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">frame</span><span class="o">$</span><span class="n">n1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ssize</span><span class="p">(</span><span class="n">e</span><span class="o">=</span><span class="m">.02</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">deff</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">rr</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">p</span><span class="p">)</span><span class="w">
</span><span class="n">frame</span><span class="o">$</span><span class="n">e1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">serr</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">deff</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">rr</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">p</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   strata     N deff   rr   p   n1   e1
## 1      1 10000  1.1 0.80 0.3 2308 0.02
## 2      2  5000  1.0 0.90 0.6 1753 0.02
## 3      3  2000  1.3 0.85 0.1  923 0.02
## 4      4  1000  0.8 0.80 0.2  606 0.02</code></pre></figure> <p>As easy as falling off a log!</p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="survey"/><summary type="html"><![CDATA[Here I show two functions in R to define sample sizes and errors of a proportion, taking into account design effect, response rate, finite population correction, and stratification. They are useful when one needs to do these calculations quickly.]]></summary></entry><entry><title type="html">Cohort component projection</title><link href="https://sdaza.com/blog/2013/projections/" rel="alternate" type="text/html" title="Cohort component projection"/><published>2013-07-02T00:00:00+00:00</published><updated>2013-07-02T00:00:00+00:00</updated><id>https://sdaza.com/blog/2013/projections</id><content type="html" xml:base="https://sdaza.com/blog/2013/projections/"><![CDATA[<p>I present an example of a cohort component projection using a closed female population (Sweden 1993), taken from Preston et al.’s book (Demography 2001, page 125). I use R and basic matrix algebra to replicate their results. The advantage of this procedure is that allows to compute easily the <em>intrinsic growth rate</em> and <em>age-proportionate distribution</em> of the stable equivalent population. All we need is the population by age at time 0 (from a census), survivorship ratios (from a life table), and age-specific fertility rates.</p> <p>The data:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"sweden1993.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">","</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">attach</span><span class="p">(</span><span class="n">dat</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    age     Nf     Lf      f
## 1    0 293395 497487     NA
## 2    5 248369 497138     NA
## 3   10 240012 496901     NA
## 4   15 261346 496531 0.0120
## 5   20 285209 495902 0.0908
## 6   25 314388 495168 0.1499
## 7   30 281290 494213 0.1125
## 8   35 286923 492760 0.0441
## 9   40 304108 490447 0.0074
## 10  45 324946 486613 0.0003
## 11  50 247613 480665     NA
## 12  55 211351 471786     NA
## 13  60 215140 457852     NA
## 14  65 221764 436153     NA
## 15  70 223506 402775     NA
## 16  75 183654 350358     NA
## 17  80 141990 271512     NA
## 18  85 112424 291707     NA</code></pre></figure> <p>As can be seen, the data have five-year-interval age groups, so each projection forward will involve 5 years. The steps are very simple:</p> <ol> <li>Project forward the population of each age group (estimation of people alive)</li> <li>Calculate the number of births of each age group based on fertility rates, adjusting by mortality (estimation of children alive)</li> <li>Create a Leslie matrix, and then multiple it by the population vector (population by age at time 0)</li> </ol> <h3 id="survivorship-ratios">Survivorship ratios</h3> <p>We have to estimate life table survival ratios, that is, proportions of birth cohorts surviving from one age interval to the next in a <strong>stationary population</strong>. Basically, we are summarizing the mortality experience of different cohorts assuming stationarity. Because census statistics refer to age “last birthday” (rather than exact age), I estimate ratios using $L_x$ (average number of survivors in an age interval) instead of $l_x$.</p> \[S_x = \frac{_5L_x}{_5L_{x-5}}\] <p>I compute the survival ratios using a loop in R. The estimation of the open-ended survival ratio is slightly different but still straightforward:</p> \[\frac{T_{85}}{T_{80}}\] <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">Sf</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NA</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">Lf</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">Sf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="o">/</span><span class="n">Lf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># open-ended survival ratio</span><span class="w">
</span><span class="n">Sf</span><span class="p">[</span><span class="nf">length</span><span class="p">(</span><span class="n">Sf</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="m">18</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">Lf</span><span class="p">[</span><span class="m">17</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="m">18</span><span class="p">])</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##  [1] 0.999 1.000 0.999 0.999 0.999 0.998 0.997 0.995 0.992 0.988 0.982 0.970 0.953 0.923 0.870 0.775 0.518</code></pre></figure> <h3 id="number-of-children">Number of children</h3> <p>This is the tricky part. Because census statistics refer to age “last birthday”, and we are projecting every 5 years, the estimation of the number of person-years lived by women in each age group consists of the average number of women alive at the beginning and end of the period (assuming a linear change over the period). To take advantage of the Leslie matrix, I define the births in R using a loop as follows:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">Bf</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">Lf</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">Bf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.05</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="m">100000</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Sf</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##  [1] 0.000000 0.000000 0.014550 0.124596 0.291792 0.318128 0.189858 0.062447 0.009340 0.000364 0.000000 0.000000
## [13] 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000</code></pre></figure> <p>1/(1+1.05) corresponds to a transformation of age-specific fertility rates (son and daughters) to maternity rates (only daughters), assuming that the ratio of male to female births (SBR) is constant across mothers’ ages. The number of births is also adjusted by the corresponding survival ratio from 0 to 5 years old ($\frac{_5L_0}{5 \times l_0}$), the number 5 goes away due to simplifying).</p> <h3 id="leslie-matrix">Leslie matrix</h3> <p>I construct a Leslie matrix by replacing specific cells of a 18 x 18 matrix (18 age groups) by the vectors defined above (survival ratios and maternity rates):</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">)</span><span class="w">
</span><span class="n">m</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Bf</span><span class="w">
</span><span class="n">s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">17</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Sf</span><span class="w">
</span><span class="n">m</span><span class="p">[</span><span class="m">2</span><span class="o">:</span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">17</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">s</span><span class="w">
</span><span class="n">m</span><span class="p">[</span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Sf</span><span class="p">[</span><span class="m">17</span><span class="p">]</span></code></pre></figure> <p>Here we have the Leslie matrix:</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">##        [,1] [,2]   [,3]  [,4]  [,5]  [,6]  [,7]   [,8]    [,9]    [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18]
##  [1,] 0.000    0 0.0145 0.125 0.292 0.318 0.190 0.0624 0.00934 0.000364 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [2,] 0.999    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [3,] 0.000    1 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [4,] 0.000    0 0.9993 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [5,] 0.000    0 0.0000 0.999 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [6,] 0.000    0 0.0000 0.000 0.999 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [7,] 0.000    0 0.0000 0.000 0.000 0.998 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [8,] 0.000    0 0.0000 0.000 0.000 0.000 0.997 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [9,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.9953 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [10,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.99218 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [11,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.987777 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [12,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.982  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [13,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.97 0.000 0.000  0.00 0.000 0.000 0.000
## [14,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.953 0.000  0.00 0.000 0.000 0.000
## [15,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.923  0.00 0.000 0.000 0.000
## [16,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.87 0.000 0.000 0.000
## [17,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.775 0.000 0.000
## [18,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.518 0.518</code></pre></figure> <p>Note that the last survival ratio is repeated in the last column (0.518). This is because the estimation of the open-ended survival ratio is:</p> \[(N_{80} + N_{85}) \times \frac{T_{85}}{T_{80}}\] <h3 id="now-lets-do-some-projections">Now, let’s do some projections</h3> <p>Using the R multiplication operator for matrices, I do a 5-year projection by simply multiplying the Leslie matrix by the population vector (remember that matrix multiplication is not commutative).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Nf</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         [,1]
##  [1,] 293574
##  [2,] 293189
##  [3,] 248251
##  [4,] 239833
##  [5,] 261015
##  [6,] 284787
##  [7,] 313782
##  [8,] 280463
##  [9,] 285576
## [10,] 301731
## [11,] 320974
## [12,] 243039
## [13,] 205109
## [14,] 204944
## [15,] 204793
## [16,] 194419
## [17,] 142324
## [18,] 131768</code></pre></figure> <p>I obtain the same results of the book. Raising this multiplication I can get the projected population of subsequent periods. Because R doesn’t have a power operator for matrices, I define a function called <em>mp</em> to raise matrices (it is not very efficient, but for this example it’s still useful).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">mp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="n">pow</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">ans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mat</span><span class="w">
    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="n">pow</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">ans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mat</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">ans</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="nf">return</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></code></pre></figure> <p>Let’s project the initial population for two periods (10 years):</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="p">(</span><span class="n">mp</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Nf</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         [,1]
##  [1,] 280121
##  [2,] 293368
##  [3,] 293049
##  [4,] 248066
##  [5,] 239529
##  [6,] 260629
##  [7,] 284238
##  [8,] 312859
##  [9,] 279147
## [10,] 283344
## [11,] 298043
## [12,] 315045
## [13,] 235861
## [14,] 195388
## [15,] 189260
## [16,] 178141
## [17,] 150666
## [18,] 141960</code></pre></figure> <p>Again, I get the same result of the book. The nice thing of all this is that estimating eigenvalues and eigenvectors, I can obtain the intrinsic growth rate and age-distribution of the “stable equivalent” population. Using the <em>eigen</em> function in R, I can identify the dominant eigenvalue (higher absolute number), and the corresponding eigenvector:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eigen</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="w">

</span><span class="c1"># intrinsic growth rate</span><span class="w">
</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">))</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="o">/</span><span class="m">5</span><span class="w">  </span><span class="c1"># 5-year-projection</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.000223</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># intrinsic proportionate age distribution</span><span class="w">
</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">vector</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="o">/</span><span class="nf">sum</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">vector</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="p">]))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##  [1] 0.0619 0.0618 0.0617 0.0616 0.0614 0.0613 0.0611 0.0608 0.0605 0.0600 0.0592 0.0580 0.0562 0.0535 0.0494 0.0429
## [17] 0.0332 0.0356</code></pre></figure> <p>The population is growing but little.</p> <h3 id="what-about-the-population-momentum">What about the population momentum?</h3> <p>The population momentum corresponds to the growth of a population after imposing replacement fertility conditions, that is, NRR=1. Thus, the first thing we have to do is to estimate NRR.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># calculating NRR</span><span class="w">
</span><span class="p">(</span><span class="n">NRR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">f</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Lf</span><span class="o">/</span><span class="m">100000</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.05</span><span class="p">)),</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1.01</code></pre></figure> <p>We can quickly estimate the intrinsic growth rate using NRR:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># quick estimation of the intrinsic growth rate</span><span class="w">
</span><span class="nf">log</span><span class="p">(</span><span class="n">NRR</span><span class="p">)</span><span class="o">/</span><span class="m">27</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.000237</code></pre></figure> <p>Very close to our estimation using cohort component projection. To impose the replacement condition, I just have to divide the first row of the Leslie matrix by NRR.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">m</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="o">/</span><span class="n">NRR</span></code></pre></figure> <p>To get the population momentum we have to project the initial population until the growth is zero (here I raised the matrix 100 times), and then to compute the ratio between the initial population and the non-growing population (stationary).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># population momentum</span><span class="w">
</span><span class="nf">sum</span><span class="p">(</span><span class="n">mp</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Nf</span><span class="p">)</span><span class="o">/</span><span class="nf">sum</span><span class="p">(</span><span class="n">Nf</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1.01</code></pre></figure> <p>After imposing the replacement condition, the population grew 1%.</p>]]></content><author><name>Sebastian Daza</name></author><category term="demography"/><summary type="html"><![CDATA[A simple example using R and matrices]]></summary></entry></feed>